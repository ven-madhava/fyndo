{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "# -----------------\n",
    "import psycopg2 as psql\n",
    "#import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import csv\n",
    "import collections\n",
    "from collections import Counter\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "\n",
    "\n",
    "# Necessary Flask imports\n",
    "# -----------------------\n",
    "from flask import Flask, request, send_file\n",
    "from flask_restful import Resource, Api, reqparse\n",
    "from json import dumps\n",
    "from flask_jsonpify import jsonify\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "# remembering commands\n",
    "# 1. cd Documents/pmate2/pmate2_env/notebooks/fyndo\n",
    "# 2. jupyter nbconvert --to script fyndo_dbapis.ipynb\n",
    "# 3. clean up py file\n",
    "# 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Local / VM set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'SWITCH BETWEEN LOCAL AND VM HERE'\n",
    "\n",
    "# make sure the json files are intact in the remote VM\n",
    "# ----------------------------------------------------\n",
    "global vm_or_local\n",
    "vm_or_local = 'local'\n",
    "\n",
    "# setting api text file path\n",
    "# --------------------------\n",
    "global api_file_path\n",
    "if vm_or_local == 'local':\n",
    "    api_file_path = '/Users/venkateshmadhava/Documents/fyndo_20/fyndo_api_key.txt'\n",
    "else:\n",
    "    api_file_path = '/home/venkateshmadhava/files/fyndo_api_key.txt'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is required for search\n",
    "# ---------------------------\n",
    "\n",
    "global stopwords\n",
    "stopwords = ['all', 'just', 'being', 'over', 'both', 'through', 'yourselves', 'its', 'before', 'herself', 'had', 'should', 'to', 'only', 'under', 'ours', 'has', 'do', 'them', 'his', 'very', 'they', 'not', 'during', 'now', 'him', 'nor', 'did', 'this', 'she', 'each', 'further', 'where', 'few', 'because', 'doing', 'some', 'are', 'our', 'ourselves', 'out', 'what', 'for', 'while', 'does', 'above', 'between', 't', 'be', 'we', 'who', 'were', 'here', 'hers', 'by', 'on', 'about', 'of', 'against', 's', 'or', 'own', 'into', 'yourself', 'down', 'your', 'from', 'her', 'their', 'there', 'been', 'whom', 'too', 'themselves', 'was', 'until', 'more', 'himself', 'that', 'but', 'don', 'with', 'than', 'those', 'he', 'me', 'myself', 'these', 'up', 'will', 'below', 'can', 'theirs', 'my', 'and', 'then', 'is', 'am', 'it', 'an', 'as', 'itself', 'at', 'have', 'in', 'any', 'if', 'again', 'no', 'when', 'same', 'how', 'other', 'which', 'you', 'after', 'most', 'such', 'why', 'a', 'off', 'i', 'yours', 'so', 'the', 'having', 'once']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting api key form local\n",
    "# -------------------------\n",
    "def get_api_key():\n",
    "    \n",
    "    \n",
    "    # getting key from local file\n",
    "    # ---------------------------\n",
    "    f = open(api_file_path, 'r')\n",
    "    key = f.read()\n",
    "\n",
    "    return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simle function to argsort list\n",
    "# ------------------------------\n",
    "def argsort(seq):\n",
    "    \n",
    "    # http://stackoverflow.com/questions/3071415/efficient-method-to-calculate-the-rank-vector-of-a-list-in-python\n",
    "    return sorted(range(len(seq)), key=seq.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now need specific generice functions for various db ops\n",
    "# API function\n",
    "# ----------------------------------------------------------\n",
    "def run_insert_update_delete_query_api_function(query):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. a single function that would run queryy\n",
    "    2. the query needs to be constructed at client end\n",
    "    \n",
    "    ONLY FOR GENERIC QUERIES LIST INSERT, UPDATE & DELETE\n",
    "    *****************************************************\n",
    "    \n",
    "    returns 'ok' or 'not_ok'\n",
    "    along with error statement\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    sanity_flag = 0\n",
    "    if 'INSERT' in query or 'DELETE' in query or 'UPDATE' in query:\n",
    "        sanity_flag = 1\n",
    "    \n",
    "    # running query\n",
    "    # use this to raise exceptions and return status to api calls            \n",
    "    # -----------------------------------------------------------\n",
    "    if sanity_flag == 1:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            # going to include run query statements here itself\n",
    "            # -------------------------------------------------\n",
    "\n",
    "            # 1. creating connection\n",
    "            # ----------------------\n",
    "            \n",
    "            # 1. creating connection\n",
    "            # DO NOT CHANGE THESE\n",
    "            # ----------------------\n",
    "            host = '127.0.0.1'\n",
    "            \n",
    "            # db setups\n",
    "            # ---------\n",
    "            if vm_or_local == 'local':                \n",
    "                con = psql.connect(host = host, database = 'fyndodb')\n",
    "            else:\n",
    "                con = psql.connect(host = host, database = 'fyndodb', user = 'fyndodbuser', password='fyndodbuserpass')\n",
    "            \n",
    "            \n",
    "            # creating cursor\n",
    "            # ---------------\n",
    "            cur = con.cursor()\n",
    "\n",
    "            # 2. executing query\n",
    "            # ------------------\n",
    "            cur.execute(query)\n",
    "\n",
    "            # 3. final closures\n",
    "            # -----------------\n",
    "            con.commit()\n",
    "            cur.close()\n",
    "            con.close()\n",
    "\n",
    "            # 4. setting stattus\n",
    "            # ------------------\n",
    "            query_out = 'ok'\n",
    "            query_status = 'ok'\n",
    "\n",
    "        except Exception as e:\n",
    "            query_out = 'error: ' + str(e)\n",
    "            query_status = 'not_ok'\n",
    "\n",
    "\n",
    "        # return status\n",
    "        # return 'ok' if query executed weel\n",
    "        # else an error\n",
    "        # use for api further process\n",
    "        # -----------------------------------\n",
    "        out_d = {}\n",
    "        out_d['output'] = query_out\n",
    "        out_d['status'] = query_status\n",
    "        \n",
    "    \n",
    "    # incorrect statement\n",
    "    # ------------------\n",
    "    else:\n",
    "        out_d = {}\n",
    "        out_d['output'] = 'error: wrong statement. this function only supports insert,delete or update.'\n",
    "        out_d['status'] = 'not_ok'\n",
    "        \n",
    "        \n",
    "    \n",
    "    return out_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.\n",
    "## API FUNCTION\n",
    "## MAIN function code to execute a query\n",
    "## -------------------------------------\n",
    "class exAPI_run_insert_update_delete_query(Resource):\n",
    "    \n",
    "    # overriding post function\n",
    "    # ------------------------\n",
    "    def post(self):\n",
    "\n",
    "        ## Authenticating request\n",
    "        ## ----------------------\n",
    "        try:\n",
    "\n",
    "            # Get stored key\n",
    "            # --------------\n",
    "            vm_api_key = get_api_key()\n",
    "\n",
    "            try:\n",
    "                \n",
    "                # retrieveing api key\n",
    "                # -------------------\n",
    "                api_key = request.args['api_key']\n",
    "                \n",
    "                # checking api correctness\n",
    "                # ------------------------\n",
    "                if api_key == vm_api_key:\n",
    "\n",
    "                    # Authorized request\n",
    "                    ####################\n",
    "                    \n",
    "                    # 1.\n",
    "                    # Setting up key values to accept\n",
    "                    # -------------------------------\n",
    "                    parser = reqparse.RequestParser()\n",
    "                    parser.add_argument('query')\n",
    "                    args = parser.parse_args()\n",
    "\n",
    "                    # 2.\n",
    "                    # Getting params\n",
    "                    # --------------\n",
    "                    query = args['query']\n",
    "                    \n",
    "                    # 3.\n",
    "                    # sanity for internal\n",
    "                    # -------------------\n",
    "                    print('API exAPI_run_insert_update_delete_query firing: ' + str(query))\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        # Using get task id function\n",
    "                        # --------------------------\n",
    "                        d = run_insert_update_delete_query_api_function(query)\n",
    "                        return jsonify(d)\n",
    "\n",
    "                    except Exception as e:\n",
    "\n",
    "                        return \"Something went wrong. error: \" + str(e), 500\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Incorrect credentials\n",
    "                    # ---------------------\n",
    "                    return 'Incorrect credentials', 401\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                # Invalid headers\n",
    "                # ---------------\n",
    "                return 'Invalid credentails. error: ' + str(e), 400\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            # Secret key not set in storage\n",
    "            # -----------------------------\n",
    "            return 'API keys not initialsed. error: ' + str(e), 401\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now need specific generice functions for various db ops\n",
    "# API function\n",
    "# ----------------------------------------------------------\n",
    "def run_select_query_api_function(table_name,query,chunk_size):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. a single function that would run all select queryies\n",
    "    2. the query needs to be constructed at client end\n",
    "    \n",
    "    ONLY FOR SELECT STATEMENT\n",
    "    *************************\n",
    "    \n",
    "    returns 'ok' or 'not_ok'\n",
    "    along with error statement or output d\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. initialisations\n",
    "    # ------------------\n",
    "    sanity_flag = 0\n",
    "    if 'SELECT' in query:\n",
    "        sanity_flag = 1\n",
    "    \n",
    "    \n",
    "    # 1. if else\n",
    "    # ----------\n",
    "    if table_name in query and sanity_flag == 1:\n",
    "    \n",
    "        # running query\n",
    "        # use this to raise exceptions and return status to api calls            \n",
    "        # -----------------------------------------------------------\n",
    "        try:\n",
    "\n",
    "            # going to include run query statements here itself\n",
    "            # -------------------------------------------------\n",
    "\n",
    "            # 1. creating connection\n",
    "            # DO NOT CHANGE THESE\n",
    "            # ----------------------\n",
    "            host = '127.0.0.1'\n",
    "            \n",
    "            # db setups\n",
    "            # ---------\n",
    "            if vm_or_local == 'local':                \n",
    "                con = psql.connect(host = host, database = 'fyndodb')\n",
    "            else:\n",
    "                con = psql.connect(host = host, database = 'fyndodb', user = 'fyndodbuser', password='fyndodbuserpass')\n",
    "            \n",
    "            # creating cursor\n",
    "            # ---------------\n",
    "            cur = con.cursor()\n",
    "\n",
    "            # 2. executing query\n",
    "            # ------------------\n",
    "            cur.execute(query)\n",
    "            cols = [desc[0] for desc in cur.description]\n",
    "\n",
    "            # 3. fetching results\n",
    "            # -------------------\n",
    "            if chunk_size == 'all':\n",
    "                query_out = cur.fetchall()\n",
    "            else:\n",
    "                query_out = cur.fetchmany(int(chunk_size))\n",
    "\n",
    "\n",
    "            # 3. final closures\n",
    "            # -----------------\n",
    "            con.commit()\n",
    "            cur.close()\n",
    "            con.close()\n",
    "\n",
    "            # 4. setting stattus\n",
    "            # ------------------\n",
    "            query_status = 'ok'\n",
    "\n",
    "        except Exception as e:\n",
    "            query_out = 'error: ' + str(e)\n",
    "            query_status = 'not_ok'\n",
    "\n",
    "\n",
    "        # return status\n",
    "        # return 'ok' if query executed weel\n",
    "        # else an error\n",
    "        # use for api further process\n",
    "        # -----------------------------------\n",
    "        if query_status == 'ok':\n",
    "            \n",
    "            # contructing out dict\n",
    "            # --------------------\n",
    "            temp_d = {}\n",
    "            \n",
    "            # iterting query out --\n",
    "            # this is list of records\n",
    "            # -----------------------\n",
    "            for i in range(len(query_out)):\n",
    "                \n",
    "                # ops\n",
    "                # ---\n",
    "                temp_d[i] = {}\n",
    "\n",
    "                # populating d\n",
    "                # ------------\n",
    "                for i_in in range(len(query_out[i])):\n",
    "                    temp_d[i][cols[i_in]] = query_out[i][i_in]\n",
    "                    \n",
    "            \n",
    "            # done and final assignments\n",
    "            # --------------------------\n",
    "            out_d = {}\n",
    "            out_d['output'] = temp_d\n",
    "            out_d['status'] = 'ok'\n",
    "            \n",
    "        else:\n",
    "            out_d = {}\n",
    "            out_d['output'] = query_out\n",
    "            out_d['status'] = query_status\n",
    "\n",
    "    \n",
    "    # if table name  not in query\n",
    "    # ---------------------------\n",
    "    else:\n",
    "        \n",
    "        out_d = {}\n",
    "        out_d['output'] = 'error: either wrong statement or table name and query are not consistent.'\n",
    "        out_d['status'] = 'not_ok'\n",
    "        \n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return out_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.\n",
    "## API FUNCTION\n",
    "## MAIN function code to execute a query\n",
    "## -------------------------------------\n",
    "class exAPI_run_select_query(Resource):\n",
    "    \n",
    "    # overriding post function\n",
    "    # ------------------------\n",
    "    def post(self):\n",
    "\n",
    "        ## Authenticating request\n",
    "        ## ----------------------\n",
    "        try:\n",
    "\n",
    "            # Get stored key\n",
    "            # --------------\n",
    "            vm_api_key = get_api_key()\n",
    "\n",
    "            try:\n",
    "                \n",
    "                # retrieveing api key\n",
    "                # -------------------\n",
    "                api_key = request.args['api_key']\n",
    "                \n",
    "                # checking api correctness\n",
    "                # ------------------------\n",
    "                if api_key == vm_api_key:\n",
    "\n",
    "                    # Authorized request\n",
    "                    ####################\n",
    "                    \n",
    "                    # 1.\n",
    "                    # Setting up key values to accept\n",
    "                    # -------------------------------\n",
    "                    parser = reqparse.RequestParser()\n",
    "                    parser.add_argument('query')\n",
    "                    parser.add_argument('table_name')\n",
    "                    parser.add_argument('chunk_size')\n",
    "                    args = parser.parse_args()\n",
    "\n",
    "                    # 2.\n",
    "                    # Getting params\n",
    "                    # --------------\n",
    "                    query = args['query']\n",
    "                    table_name = args['table_name']\n",
    "                    chunk_size = args['chunk_size']\n",
    "                    \n",
    "                    # 3.\n",
    "                    # sanity for internal\n",
    "                    # -------------------\n",
    "                    print('API exAPI_run_select_query firing: ' + str(query))\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        # Using get task id function\n",
    "                        # --------------------------\n",
    "                        d = run_select_query_api_function(table_name,query,chunk_size)\n",
    "                        return jsonify(d)\n",
    "\n",
    "                    except Exception as e:\n",
    "\n",
    "                        return \"Something went wrong. error: \" + str(e), 500\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Incorrect credentials\n",
    "                    # ---------------------\n",
    "                    return 'Incorrect credentials', 401\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                # Invalid headers\n",
    "                # ---------------\n",
    "                return 'Invalid credentails. error: ' + str(e), 400\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            # Secret key not set in storage\n",
    "            # -----------------------------\n",
    "            return 'API keys not initialsed. error: ' + str(e) , 401\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_search_score(input_q_list):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. we need 2 metrics - order & word overlap match\n",
    "    2. we will use simple search score to return\n",
    "    \n",
    "    FOR NOW NOT WORRYING ABOUT THE ORDER OF SEARCH QUERY\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. initis & set ups\n",
    "    # -------------------\n",
    "    assert 'list' in str(type(input_q_list)).lower(),'Error: input here is not a list.'\n",
    "    q_in = input_q_list[0] # is a word -- string\n",
    "    srch_str_in = input_q_list[1] # is a statement -- string\n",
    "    \n",
    "    \n",
    "    global stopwords\n",
    "    srch_str = srch_str_in.lower().split(' ')\n",
    "    q = q_in.lower().split(' ')\n",
    "    d = {}\n",
    "    counter = 0\n",
    "    \n",
    "    # 1. looping thru each word in q\n",
    "    # ------------------------------\n",
    "    for each_q_word in q:\n",
    "        \n",
    "        # initialising dict\n",
    "        # -----------------\n",
    "        d[counter] = {}\n",
    "        d[counter]['word'] = each_q_word\n",
    "        d[counter]['seq'] = []\n",
    "        \n",
    "            \n",
    "        # main iter\n",
    "        # ---------\n",
    "        for each_s_word in srch_str:\n",
    "            \n",
    "            # 1.1 sim check - processing only if not stopword\n",
    "            # -----------------------------------------------\n",
    "            if each_s_word not in stopwords and each_q_word not in stopwords:\n",
    "                \n",
    "                # sequence matching\n",
    "                # -----------------\n",
    "                match = SequenceMatcher(None, each_s_word, each_q_word).find_longest_match(0, len(each_s_word), 0, len(each_q_word))\n",
    "                d[counter]['seq'].append(match.size/max(len(each_s_word),len(each_q_word)))\n",
    "                \n",
    "            else:\n",
    "\n",
    "                # just appending 0\n",
    "                # ----------------\n",
    "                d[counter]['seq'].append(0.0)\n",
    "        \n",
    "        \n",
    "        # sanity counter incremenet\n",
    "        # -------------------------\n",
    "        counter += 1\n",
    "    \n",
    "    \n",
    "    # building final score -- which will be an avg\n",
    "    # --------------------------------------------\n",
    "    temp_s = 0\n",
    "    for keys in d:\n",
    "        temp_s += sum(d[keys]['seq'])\n",
    "    \n",
    "    \n",
    "    # 2. final return\n",
    "    # ----------------\n",
    "    return temp_s\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main function has to have \n",
    "# -----------------------------\n",
    "\n",
    "# 1. raw query returned by client\n",
    "# 2. the fields to concat in search\n",
    "# 3. must be a pooled function\n",
    "\n",
    "\n",
    "def run_search_query_api_function(table_name,query,chunk_size,feild_names,search_query):\n",
    "    \n",
    "    '''\n",
    "    1. the input to these functions are what the api function will  in its args\n",
    "    2. this must return a jsonable dict with same feilds - output, status\n",
    "    3. must be a pooled function\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    # 0. inits\n",
    "    # --------\n",
    "    out_dict = {}\n",
    "    feild_names = feild_names.split(',')\n",
    "    \n",
    "    \n",
    "    # 1. calling generic query api\n",
    "    # the output here is a dict with status and output as keys\n",
    "    # ---------------------------------------------------------\n",
    "    raw_results_out = run_select_query_api_function(table_name,query,chunk_size)\n",
    "    \n",
    "    \n",
    "    # 2. proceeding further based on raw_results status\n",
    "    # -------------------------------------------------\n",
    "    try:\n",
    "        if raw_results_out['status'] == 'ok' and len(raw_results_out['output'].keys()) > 0:\n",
    "            \n",
    "            # ok to proceed as there are reults to parse\n",
    "            # 2.1 local inits\n",
    "            # ----------------\n",
    "            new_sorted_d = {}\n",
    "            raw_results = raw_results_out['output']\n",
    "            \n",
    "            \n",
    "            # 2.1 building args\n",
    "            # -----------------\n",
    "            args = [[search_query, ' '.join([raw_results[each_ind][each_f] for each_f in feild_names])] for each_ind in range(len(raw_results))]\n",
    "            \n",
    "            \n",
    "            # 2.2 calling pooling function\n",
    "            # ----------------------------\n",
    "            pool = ThreadPool(10)\n",
    "\n",
    "            # starmap accepts a sequence of argument tuples\n",
    "            # ---------------------------------------------\n",
    "            results = pool.starmap(return_search_score, product(args, repeat = 1))\n",
    "            \n",
    "            # closing pools\n",
    "            # -------------\n",
    "            pool.terminate()\n",
    "            pool.join()\n",
    "            \n",
    "            # 3. sorting results based on highest score at top\n",
    "            # ------------------------------------------------\n",
    "            argsort_results = list(reversed(argsort(results)))\n",
    "            \n",
    "            # 3.3 looping & assigning\n",
    "            # will use looping here\n",
    "            # -----------------------\n",
    "            for i in range(len(argsort_results)):\n",
    "                new_sorted_d[i] = raw_results[argsort_results[i]]\n",
    "                \n",
    "                \n",
    "            \n",
    "            # 4. done and final output assignment\n",
    "            # -----------------------------------\n",
    "            out_dict['output'] = new_sorted_d\n",
    "            out_dict['status'] = 'ok'\n",
    "            \n",
    "        \n",
    "    except:\n",
    "        \n",
    "        # something was not right / or no results to parse\n",
    "        # -------------------------------------------------\n",
    "        out_dict['output'] = 'no results'\n",
    "        out_dict['status'] = 'not_ok'\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return out_dict\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.\n",
    "## API FUNCTION\n",
    "## MAIN function code to execute a search\n",
    "## --------------------------------------\n",
    "class exAPI_run_search_query(Resource):\n",
    "    \n",
    "    # overriding post function\n",
    "    # ------------------------\n",
    "    def post(self):\n",
    "\n",
    "        ## Authenticating request\n",
    "        ## ----------------------\n",
    "        try:\n",
    "\n",
    "            # Get stored key\n",
    "            # --------------\n",
    "            vm_api_key = get_api_key()\n",
    "\n",
    "            try:\n",
    "                \n",
    "                # retrieveing api key\n",
    "                # -------------------\n",
    "                api_key = request.args['api_key']\n",
    "                \n",
    "                # checking api correctness\n",
    "                # ------------------------\n",
    "                if api_key == vm_api_key:\n",
    "\n",
    "                    # Authorized request\n",
    "                    ####################\n",
    "                    \n",
    "                    # 1.\n",
    "                    # Setting up key values to accept\n",
    "                    # -------------------------------\n",
    "                    parser = reqparse.RequestParser()\n",
    "                    parser.add_argument('query')\n",
    "                    parser.add_argument('table_name')\n",
    "                    parser.add_argument('chunk_size')\n",
    "                    parser.add_argument('feild_names')\n",
    "                    parser.add_argument('search_query')\n",
    "                    \n",
    "                    args = parser.parse_args()\n",
    "\n",
    "                    # 2.\n",
    "                    # Getting params\n",
    "                    # --------------\n",
    "                    query = args['query']\n",
    "                    table_name = args['table_name']\n",
    "                    chunk_size = args['chunk_size']\n",
    "                    feild_names = args['feild_names']\n",
    "                    search_query = args['search_query']\n",
    "                    \n",
    "                    \n",
    "                    # 3.\n",
    "                    # sanity for internal\n",
    "                    # -------------------\n",
    "                    print('API exAPI_run_search_query firing: ' + str(feild_names) + ' -- ' + str(search_query) + ' -- ' + str(query))\n",
    "                    \n",
    "                    \n",
    "                    try:\n",
    "                        # Using get task id function\n",
    "                        # --------------------------\n",
    "                        d = run_search_query_api_function(table_name,query,chunk_size,feild_names,search_query)\n",
    "                        return jsonify(d)\n",
    "\n",
    "                    except Exception as e:\n",
    "\n",
    "                        return \"Something went wrong. error: \" + str(e), 500\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Incorrect credentials\n",
    "                    # ---------------------\n",
    "                    return 'Incorrect credentials', 401\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                # Invalid headers\n",
    "                # ---------------\n",
    "                return 'Invalid credentails. error: ' + str(e), 400\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            # Secret key not set in storage\n",
    "            # -----------------------------\n",
    "            return 'API keys not initialsed. error: ' + str(e) , 401\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. running apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary set ups\n",
    "# -----------------\n",
    "app = Flask(__name__)\n",
    "api = Api(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding resource\n",
    "# ---------------\n",
    "api.add_resource(exAPI_run_insert_update_delete_query, '/run_insert_update_delete_query') # Route\n",
    "api.add_resource(exAPI_run_select_query, '/run_select_query') # Route\n",
    "api.add_resource(exAPI_run_search_query, '/run_search_query') # Route\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final step to run\n",
    "# -----------------\n",
    "global vm_or_local\n",
    "if __name__ == '__main__':\n",
    "    if vm_or_local == 'local':\n",
    "        app.run(port='5002') # For local\n",
    "    else:\n",
    "        app.run(host='0.0.0.0', port=8000) # VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END OF CODE ###\n",
    "### DELETE FROM HERE ####\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. local notebook psql ops -- delete from this point on before uploading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Internal table ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of feilds buidler \n",
    "# ---------------------\n",
    "def cols_feilds_builder(table_name):\n",
    "    \n",
    "    # 1. getting cols\n",
    "    # ---------------\n",
    "    f,m = return_psql_query(table_name,8,10)\n",
    "    out = run_psql_queries(f,1000,'all',False)\n",
    "\n",
    "\n",
    "    # 2. building col string\n",
    "    # ----------------------\n",
    "    cols = '('\n",
    "    for each in out:\n",
    "        cols += str(each) +', '\n",
    "    cols = cols[:-2]\n",
    "    cols += ')'\n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super helpful chunker function that returns seq chunks correctly sized even at ends\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "def chunker(seq, size):\n",
    "    \n",
    "    # from http://stackoverflow.com/a/434328\n",
    "    # not touch this code\n",
    "    # -------------------\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a new simpler return_psql_query function\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def return_psql_query(table_name,mode,data):\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    1. will take in params and data in specific format\n",
    "    2. will return a psql query statement\n",
    "    \n",
    "    mode legend\n",
    "    -----------\n",
    "    0 - create table\n",
    "    401 - remane table\n",
    "    404 - drop table if exists\n",
    "    \n",
    "    1 - insert rows\n",
    "    2 - update rows\n",
    "    3 - delete rows\n",
    "    4 - delete all rows\n",
    "    \n",
    "    5 - add column\n",
    "    6 - delete column\n",
    "    \n",
    "    7 - select all records\n",
    "    8 - select records with limit\n",
    "    9 - select just count of records\n",
    "    \n",
    "    10 - select records with conditions\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 0. inits\n",
    "    # --------\n",
    "    psql_dtypes = ['varchar','float8','int']\n",
    "    \n",
    "    \n",
    "    # 1. main if statement\n",
    "    # --------------------\n",
    "    \n",
    "    # create table\n",
    "    # -----------\n",
    "    if mode == 0:\n",
    "        \n",
    "        # create table\n",
    "        # CREATE TABLE test_projx_profiles (user_id varchar, user_name varchar, \n",
    "        # user_title varchar, user_brief varchar, user_industry varchar);\n",
    "        \n",
    "        # 1.1 data format\n",
    "        # data = string in format \n",
    "        # -- '(field_name dtype PRIMARY KEY, feild_name dtype,...)'\n",
    "        \n",
    "        # building final query\n",
    "        # --------------------\n",
    "        final_queries = 'CREATE TABLE ' + str(table_name) + ' ' + data + ';'\n",
    "    \n",
    "    \n",
    "    # rename table\n",
    "    # ------------\n",
    "    elif mode == 401:\n",
    "        \n",
    "        # here data is just new table name\n",
    "        # --------------------------------\n",
    "        final_queries = 'ALTER TABLE ' + table_name + ' RENAME TO ' + data + ';'\n",
    "        \n",
    "    # delete table\n",
    "    # ------------\n",
    "    elif mode == 404:\n",
    "        \n",
    "        # drop table\n",
    "        # -----------\n",
    "        final_queries = 'DROP TABLE ' + table_name + ';'\n",
    "    \n",
    "    \n",
    "    # insert rows\n",
    "    # -----------\n",
    "    elif mode == 1:\n",
    "        \n",
    "        \n",
    "        # insert rows\n",
    "        # -----------\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        INSERT INTO table_name (field_name_1, field_name_2)\n",
    "        VALUES\n",
    "        \n",
    "        ('http://www.google.com','Google'),\n",
    "        ('http://www.yahoo.com','Yahoo'),\n",
    "        ('http://www.bing.com','Bing');\n",
    "\n",
    "        '''\n",
    "        # inserts recods\n",
    "        # data to be dict\n",
    "        # format d['cols'] = [field_1,feild_2]\n",
    "        # d['rows'] = [(data01,data02),(data11,data12),(data21,data22),.....]\n",
    "        # ----------------------------------------------------------------------\n",
    "        final_queries = 'INSERT INTO ' + table_name + ' ' + str(data['cols']) + ' VALUES '\n",
    "        \n",
    "        \n",
    "        # 2. appending rows\n",
    "        # ----------------\n",
    "        for i in range(len(data['rows'])):\n",
    "            \n",
    "            final_queries += str(data['rows'][i])\n",
    "            \n",
    "            # ops\n",
    "            # ---\n",
    "            if i == len(data['rows']) - 1:\n",
    "                final_queries += ';'\n",
    "            else:\n",
    "                final_queries += ','\n",
    "    \n",
    "    \n",
    "    # update rows\n",
    "    # -----------\n",
    "    elif mode == 2:\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        UPDATE table\n",
    "        SET column1 = value1,\n",
    "            column2 = value2 ,...\n",
    "        WHERE\n",
    "        condition;\n",
    "    \n",
    "        UPDATE link\n",
    "        SET last_update = DEFAULT\n",
    "        WHERE last_update IS NULL;\n",
    "    \n",
    "        '''\n",
    "        \n",
    "        # data to be in format\n",
    "        # data['condition'] = ('feild','value')\n",
    "        # data['rows'] = [('column1','value1'),('column2','value2'),..]\n",
    "        # --------------------------------------------------------------\n",
    "        final_queries = 'UPDATE ' + table_name + ' SET '\n",
    "        for each in data['rows']:\n",
    "            final_queries += str(each[0] + ' = ' + each[1]) + ', '\n",
    "        final_queries = final_queries[:-2]\n",
    "        \n",
    "        # appending where\n",
    "        # ---------------\n",
    "        final_queries += ' WHERE ' + str(data['condition'][0]) + ' IS ' + str(data['condition'][1]) + ';'\n",
    "    \n",
    "    \n",
    "    \n",
    "    # delete row with condition\n",
    "    # -------------------------\n",
    "    elif mode == 3:\n",
    "        \n",
    "        # delete row with condition\n",
    "        # data in format LIST\n",
    "        # ['id','value]\n",
    "        # ------------------------\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        DELETE FROM link\n",
    "        WHERE id = 8;\n",
    "\n",
    "        '''\n",
    "        \n",
    "        final_queries = 'DELETE FROM ' + table_name + ' WHERE ' + str(data[0]) + ' = ' + str(data[1]) + ';'\n",
    "        \n",
    "    \n",
    "    \n",
    "    # delete all rows\n",
    "    # ---------------\n",
    "    elif mode == 4:\n",
    "        \n",
    "        ''' DELETE FROM link; '''\n",
    "        \n",
    "        final_queries = 'DELETE FROM ' + table_name + ';'\n",
    "    \n",
    "    \n",
    "    \n",
    "    # adding new col\n",
    "    # --------------\n",
    "    elif mode == 5:\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        ALTER TABLE customer \n",
    "        ADD COLUMN fax VARCHAR,\n",
    "        ADD COLUMN email VARCHAR;\n",
    "        \n",
    "        ALTER TABLE customers\n",
    "        ADD COLUMN contact_name NOT NULL DEFAULT 'foo';\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # addind a col to db\n",
    "        # date to be in list\n",
    "        # [('name','varchar'),('age','int')]\n",
    "        # NOT ACCOMODATING DEFAULT VALUE FOR NOW\n",
    "        # --------------------------------------s\n",
    "        final_queries = 'ALTER TABLE ' + table_name\n",
    "        \n",
    "        # itering thru data list\n",
    "        # ----------------------\n",
    "        for each in data:\n",
    "            final_queries += ' ADD COLUMN ' + str(each[0]) + ' ' + str(each[1]) + ', '\n",
    "        final_queries = final_queries[:-2]\n",
    "        final_queries += ';'\n",
    "    \n",
    "    \n",
    "    # delete column\n",
    "    # -------------\n",
    "    elif mode == 6:\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        ALTER TABLE table_name DROP COLUMN column_name;\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # data in format list\n",
    "        # ['col_name', 'colname',...]\n",
    "        # ----------------------------\n",
    "        final_queries = 'DROP COLUMN IF EXISTS ' + ', '.join(data) + ';'\n",
    "    \n",
    "    \n",
    "    \n",
    "    # select all records\n",
    "    # ------------------\n",
    "    elif mode == 7:\n",
    "        \n",
    "        # selects all rows\n",
    "        # ----------------\n",
    "        final_queries = 'SELECT * FROM ' + table_name + ';'\n",
    "        \n",
    "    \n",
    "    \n",
    "    # select all records \n",
    "    # WITH LIMIT\n",
    "    # ------------------\n",
    "    elif mode == 8:\n",
    "        \n",
    "        # data is just a value like 50\n",
    "        # select all rows with limit\n",
    "        # --------------------------\n",
    "        final_queries = 'SELECT * FROM ' + table_name + ' LIMIT ' + str(data) + ';'\n",
    "    \n",
    "    \n",
    "    # select just count of records\n",
    "    # ----------------------------\n",
    "    elif mode == 9:\n",
    "        \n",
    "        # returns count only\n",
    "        # ------------------\n",
    "        final_queries = 'SELECT COUNT(*) FROM ' + table_name + ';'\n",
    "    \n",
    "    \n",
    "    \n",
    "    # sleect rows with conditions\n",
    "    # ---------------------------\n",
    "    elif mode == 10:\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        # https://www.postgresqltutorial.com/postgresql-where/\n",
    "        \n",
    "        WHERE OPERATOR CLAUSES\n",
    "        -----------------------\n",
    "        Operator  Description\n",
    "        = Equal\n",
    "        > Greater than\n",
    "        < Less than\n",
    "        >= Greater than or equal\n",
    "        <= Less than or equal\n",
    "        <> or != Not equal\n",
    "        AND Logical operator AND\n",
    "        OR Logical operator OR\n",
    "        \n",
    "        \n",
    "        SELECT select_list\n",
    "        FROM table_name\n",
    "        WHERE condition;\n",
    "        \n",
    "        SELECT\n",
    "            last_name,\n",
    "            first_name\n",
    "        FROM\n",
    "            customer\n",
    "        WHERE\n",
    "            first_name = 'Jamie';\n",
    "        \n",
    "        \n",
    "        SELECT\n",
    "            first_name,\n",
    "            last_name\n",
    "        FROM\n",
    "            customer\n",
    "        WHERE\n",
    "            last_name = 'Rodriguez' OR \n",
    "            first_name = 'Adam';\n",
    "    \n",
    "    \n",
    "        '''\n",
    "        \n",
    "        # data must be in format\n",
    "        # data['cols'] = [col1', 'col2'] or ['*']\n",
    "        \n",
    "        # data['ops'] = '=' or '<=' etc\n",
    "        # data['condition'] = 'AND', 'OR'\n",
    "        # ---------------------------------------\n",
    "        final_queries = 'SELECT ' + ', '.join(data['cols'] ) + ' FROM ' + table_name + ';'# + ' WHERE '\n",
    "    \n",
    "    \n",
    "    \n",
    "    # final return\n",
    "    # ------------\n",
    "    return final_queries, mode\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERIC - function to execute psql queries\n",
    "# -------------------------------------------\n",
    "\n",
    "def run_psql_queries(final_queries,mode,chunk_size,print_status):\n",
    "    \n",
    "    \n",
    "    # RUN THE BELOW PROXY COMMAND\n",
    "    # THIS IS ONLY IF USING GCLOUD PSQL\n",
    "    # ---------------------------------\n",
    "    # ./cloud_sql_proxy -instances=ven-ml-project:us-central1:pmate-psql=tcp:5432\n",
    "    \n",
    "    # 1. Creating a new connection\n",
    "    # Proxy needs to be running inorder for below to run\n",
    "    # Below works\n",
    "    # local settings\n",
    "    # can be the same for local / vm\n",
    "    # --------------------------------------------------\n",
    "    host = '127.0.0.1'\n",
    "    db = 'solvr'\n",
    "    #user = 'postgres'\n",
    "    #password = 'v230385v'\n",
    "\n",
    "    # 2. create a connection\n",
    "    # ----------------------\n",
    "    #con = psql.connect(host = host, database = db, user = user, password = password)\n",
    "    con = psql.connect(host = host, database = db)\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    # 3. executing query\n",
    "    # ------------------\n",
    "    cur.execute(final_queries)\n",
    "    if print_status == True:\n",
    "        print('Executed:\\n' + str(final_queries))\n",
    "    \n",
    "    \n",
    "    # 4. setting output\n",
    "    # reserve may be 0 - for generic modes\n",
    "    # -------------------------------------\n",
    "    \n",
    "    # fetching col names only\n",
    "    # -----------------------\n",
    "    if mode == 1000:\n",
    "        \n",
    "        out = [desc[0] for desc in cur.description]\n",
    "        \n",
    "    \n",
    "    # fetching rows\n",
    "    # ------------\n",
    "    elif mode == 7 or mode == 8: # selecting rows\n",
    "        \n",
    "        # showing cols\n",
    "        # ------------\n",
    "        out = [desc[0] for desc in cur.description]\n",
    "        print('col heads - ')\n",
    "        print(out)\n",
    "        print('**********')\n",
    "        \n",
    "        if chunk_size == 'all':\n",
    "            out = cur.fetchall()\n",
    "        else:\n",
    "            out = cur.fetchmany(chunk_size)\n",
    "    \n",
    "    \n",
    "    # viewing count\n",
    "    # ------------\n",
    "    elif mode == 9: \n",
    "        \n",
    "        out = cur.fetchone()\n",
    "    \n",
    "    \n",
    "    # all else\n",
    "    # --------\n",
    "    else:\n",
    "        out = 'ok'\n",
    "        \n",
    "    \n",
    "    # 4. final closures\n",
    "    # -----------------\n",
    "    con.commit()\n",
    "    cur.close()\n",
    "    con.close()\n",
    "    \n",
    "    # 5. returning fetches\n",
    "    # --------------------\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 create table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# having table names and col list for later use\n",
    "# ---------------------------------------------\n",
    "\n",
    "### USERS ###\n",
    "#############\n",
    "\n",
    "# users\n",
    "# -----\n",
    "users_d = {}\n",
    "users_d['table'] = 'userprofile'\n",
    "users_d['cols'] = '(user_id varchar PRIMARY KEY, user_name varchar, user_phone varchar, user_email varchar, user_title varchar, user_about varchar, user_dpurl varchar, user_educationbrief varchar, user_location varchar, user_projectstatus varchar, user_onlinestatus varchar, user_createdon TIMESTAMP, user_lastlogin TIMESTAMP)'\n",
    "#del users_d\n",
    "\n",
    "# skill\n",
    "# -----\n",
    "skill_d = {}\n",
    "skill_d['table'] = 'skill'\n",
    "skill_d['cols'] = '(skill_id varchar PRIMARY KEY, category_id varchar, skill_name varchar, skill_desc varchar)'\n",
    "#del skill_d\n",
    "\n",
    "\n",
    "# category\n",
    "# -----\n",
    "category_d = {}\n",
    "category_d['table'] = 'category'\n",
    "category_d['cols'] = '(category_id varchar PRIMARY KEY, category_name varchar, category_desc varchar)'\n",
    "#del category_d\n",
    "\n",
    "# workex\n",
    "# ------\n",
    "workex_d = {}\n",
    "workex_d['table'] = 'workex'\n",
    "workex_d['cols'] = '(workex_id varchar PRIMARY KEY, user_id varchar, workex_companyname varchar, workex_startdate DATE, workex_enddate DATE, workex_title varchar, workex_desc varchar)'\n",
    "#del workex_d\n",
    "\n",
    "# userskill\n",
    "# ------\n",
    "userskill_d = {}\n",
    "userskill_d['table'] = 'userskill'\n",
    "userskill_d['cols'] = '(userskill_id varchar PRIMARY KEY, user_id varchar, skill_id varchar, userskill_desc varchar, userskill_achievements varchar)'\n",
    "#del userskill_d\n",
    "\n",
    "################\n",
    "# NOT USING THIS\n",
    "################\n",
    "# userskillsachievement\n",
    "# ---------------------\n",
    "#userskillsachievement_d = {}\n",
    "#userskillsachievement_d['table'] = 'userskillsachievement'\n",
    "#userskillsachievement_d['cols'] = '(userskillsachievement_id varchar PRIMARY KEY, userskill_id varchar, userskillsachievement_desc varchar)'\n",
    "#del userskillsachievement_d\n",
    "\n",
    "\n",
    "# userrating\n",
    "# ---------------------\n",
    "userrating_d = {}\n",
    "userrating_d['table'] = 'userrating'\n",
    "userrating_d['cols'] = '(userrating_id varchar PRIMARY KEY, user_id varchar, userrating_provideduserid varchar, userrating_message varchar)'\n",
    "#del userrating_d\n",
    " \n",
    "### PROJECTS ###\n",
    "################\n",
    "\n",
    "# project\n",
    "# ---------------------\n",
    "project_d = {}\n",
    "project_d['table'] = 'project'\n",
    "project_d['cols'] = '(project_id varchar PRIMARY KEY, user_id varchar, project_brief varchar, project_status varchar, project_startdate DATE, project_enddate DATE)'\n",
    "#del project_d\n",
    "\n",
    "# projectskill\n",
    "# -------------\n",
    "projectskill_d = {}\n",
    "projectskill_d['table'] = 'projectskill'\n",
    "projectskill_d['cols'] = '(projectskill_id varchar PRIMARY KEY, project_id varchar, skill_id varchar, projectskill_status varchar)'\n",
    "#del projectskill_d\n",
    "\n",
    "\n",
    "# projectskilluser\n",
    "# -------------\n",
    "projectskilluser_d = {}\n",
    "projectskilluser_d['table'] = 'projectskilluser'\n",
    "projectskilluser_d['cols'] = '(projectskilluser_id varchar PRIMARY KEY, projectskill_id varchar, user_id varchar, projectskilluser_userintromessage varchar, projectskilluser_status varchar)'\n",
    "#del projectskilluser_d\n",
    "\n",
    "\n",
    "# projectmessages\n",
    "# -------------\n",
    "projectmessages_d = {}\n",
    "projectmessages_d['table'] = 'projectmessage'\n",
    "projectmessages_d['cols'] = '(projectmessage_id varchar PRIMARY KEY, projectskilluser_id varchar, user_id varchar, projectmessage_timestamp TIMESTAMP, projectmessage_message varchar)'\n",
    "#del projectmessages_d\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shopprofile\n",
    "# -----------\n",
    "\n",
    "shop_profile = {}\n",
    "shop_profile['table'] = 'shopprofile'\n",
    "shop_profile['cols'] = \"(shopprofile_id varchar PRIMARY KEY, shopprofile_name varchar, shopprofile_address varchar, shopprofile_phone varchar, shopprofile_email varchar, shopprofile_dpurl varchar, shopprofile_verified varchar NOT NULL DEFAULT 'false', shopprofile_createdon DATE, shopprofile_lastlogin TIMESTAMP)\"\n",
    "\n",
    "shop_post = {}\n",
    "shop_post['table'] = 'shoppost'\n",
    "shop_post['cols'] = \"(shoppost_id varchar PRIMARY KEY, shopprofile_id varchar, shoppost_content varchar, shoppost_createdon TIMESTAMP, shoppost_img1url varchar NOT NULL DEFAULT 'na', shoppost_img2url varchar NOT NULL DEFAULT 'na', shoppost_img3url varchar NOT NULL DEFAULT 'na', shoppost_img4url varchar NOT NULL DEFAULT 'na')\"\n",
    "\n",
    "shop_product = {}\n",
    "shop_product['table'] = 'shopproduct'\n",
    "shop_product['cols'] = \"(shopproduct_id varchar PRIMARY KEY, shopprofile_id varchar, prodcategory_name varchar, shopproduct_name varchar, shopproduct_desc varchar, shopproduct_mrp varchar, shopproduct_availability varchar, shopproduct_featured varchar, shopproduct_img1url varchar NOT NULL DEFAULT 'na',  shopproduct_img2url varchar NOT NULL DEFAULT 'na',  shopproduct_img3url varchar NOT NULL DEFAULT 'na',  shopproduct_img4url varchar NOT NULL DEFAULT 'na', shopproduct_lastedit TIMESTAMP)\"\n",
    "\n",
    "\n",
    "prod_category = {}\n",
    "prod_category['table'] = 'prodcategory'\n",
    "prod_category['cols'] = \"(prodcategory_id varchar PRIMARY KEY, prodcategory_name varchar, prodcategory_dpurl varchar NOT NULL DEFAULT 'na')\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"CREATE TABLE prodcategory (prodcategory_id varchar PRIMARY KEY, prodcategory_name varchar, prodcategory_dpurl varchar NOT NULL DEFAULT 'na');\",\n",
       " 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.\n",
    "# building query\n",
    "# --------------\n",
    "\n",
    "curr_d = prod_category\n",
    "f,m = return_psql_query(curr_d['table'],0,curr_d['cols'])\n",
    "del curr_d\n",
    "f,m"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 2.\n",
    "# running query\n",
    "# -------------\n",
    "\n",
    "run_psql_queries(fq,1,'all',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 generice table ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "# looking at all tables in the databse after creatin tables\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "run_psql_queries(\"SELECT tablename FROM pg_catalog.pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\",7,'all',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. \n",
    "# looking at cols given a table\n",
    "# ------------------------------\n",
    "\n",
    "table_name_for_count = 'userprofile'\n",
    "f,m = return_psql_query(table_name_for_count,8,10)\n",
    "out = run_psql_queries(f,m,'all',False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 local psql ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "# getting col names\n",
    "# -----------------\n",
    "#table_name = 'userprofile'\n",
    "\n",
    "# lookup\n",
    "# ------\n",
    "#cols_feilds_builder(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. inserting record query builder\n",
    "# ---------------------------------\n",
    "fq = 'INSERT INTO ' + table_name + ' ' + str(cols_feilds_builder(table_name)) + ' VALUES '\n",
    "fq\n",
    "\n",
    "\n",
    "# 3. \n",
    "# set vrow value here\n",
    "# -------------------\n",
    "row = ('up002','Mukundh Venkatesh','9790946063','mukundh@geospot.in','Student','I am student',\n",
    "      'user_dpurl_tbu','I m in TIPS school.','Chennai,TN','Active','2020-05-12',str(datetime.now()))\n",
    "\n",
    "\n",
    "# final query\n",
    "# ----------\n",
    "fq += str(row) + ';'\n",
    "fq"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSERT INTO prodcategory (prodcategory_id, prodcategory_name) VALUES \n",
    "('pc01', 'Fashion'),\n",
    "('pc02', 'Electronics'),\n",
    "('pc03', 'Furniture'),\n",
    "('pc04', 'Beauty & Health'),\n",
    "('pc05', 'Toys'),\n",
    "('pc06', 'Jewellery'),\n",
    "('pc07', 'Sports'),\n",
    "('pc08', 'Industrial');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT INTO posttype (posttype_id, posttype_name) VALUES \n",
    "('pt01', 'Discount'),\n",
    "('pt02', 'New Arrivals'),\n",
    "('pt03', 'Promo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'list' in str(type([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search concept\n",
    "# ---------------\n",
    "\n",
    "#srch_db_1 = 'This is a head less ear phones for the best experience. Sony earphones pro'\n",
    "#srch_db_2 = 'This is a great noise free product. Comes with surrond sound. Earphones and mic is attached in it. Philips Headphones Plus.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "#src_q = 'iphone'\n",
    "#return_search_score(src_q)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "raw_results = {}\n",
    "raw_results['output'] = {}\n",
    "raw_results['status'] = 'ok'\n",
    "\n",
    "\n",
    "raw_results['output'][1] = {}\n",
    "raw_results['output'][1]['content'] = 'This is a head less ear phones for the best experience'\n",
    "raw_results['output'][1]['name'] = 'Sony earphones pro'\n",
    "raw_results['output'][1]['type'] = 'electronic'\n",
    "raw_results['output'][1]['date'] = '22-2-2020'\n",
    "\n",
    "\n",
    "\n",
    "raw_results['output'][0] = {}\n",
    "raw_results['output'][0]['content'] = 'This is a great noise free product. Comes with surrond sound. Earphones and mic is attached in it.'\n",
    "raw_results['output'][0]['name'] = 'Philips Headphones Plus'\n",
    "raw_results['output'][0]['type'] = 'electronic'\n",
    "raw_results['output'][0]['date'] = '25-2-2020'\n",
    "\n",
    "# example\n",
    "raw_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmate2_env",
   "language": "python",
   "name": "pmate2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
